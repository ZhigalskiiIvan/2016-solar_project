{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFmOh482SyEF"
      },
      "source": [
        "## Lab 3\n",
        "### Part 1: Dealing with overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjzAuO3oSvsI"
      },
      "source": [
        "Today we work with [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) (*hint: it is available in `torchvision`*).\n",
        "\n",
        "Your goal for today:\n",
        "1. Train a FC (fully-connected) network that achieves >= 0.885 test accuracy.\n",
        "2. Cause considerable overfitting by modifying the network (e.g. increasing the number of network parameters and/or layers) and demonstrate in in the appropriate way (e.g. plot loss and accurasy on train and validation set w.r.t. network complexity).\n",
        "3. Try to deal with overfitting (at least partially) by using regularization techniques (Dropout/Batchnorm/...) and demonstrate the results.\n",
        "\n",
        "__Please, write a small report describing your ideas, tries and achieved results in the end of this file.__\n",
        "\n",
        "*Note*: Tasks 2 and 3 are interrelated, in task 3 your goal is to make the network from task 2 less prone to overfitting. Task 1 is independent from 2 and 3.\n",
        "\n",
        "*Note 2*: We recomment to use Google Colab or other machine with GPU acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_KBld6VOSwhW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchsummary\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdLOG0XqS_g5",
        "outputId": "323aadaf-3c2a-4737-c94a-578321cd2438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory fmnist is created!\n"
          ]
        }
      ],
      "source": [
        "# Technical function\n",
        "def mkdir(path):\n",
        "    if not os.path.exists(root_path):\n",
        "        os.mkdir(root_path)\n",
        "        print(\"Directory\", path, \"is created!\")\n",
        "    else:\n",
        "        print(\"Directory\", path, \"already exists!\")\n",
        "\n",
        "\n",
        "root_path = \"fmnist\"\n",
        "mkdir(root_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt6LE7XaTDT9",
        "outputId": "fd29a15f-fb5f-4bf4-bace-f54a089c3951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to fmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 13.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting fmnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to fmnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to fmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 210kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting fmnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to fmnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to fmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.84MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting fmnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to fmnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to fmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 5.24MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting fmnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to fmnist/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "download = True\n",
        "train_transform = transforms.ToTensor()\n",
        "test_transform = transforms.ToTensor()\n",
        "transforms.Compose((transforms.ToTensor()))\n",
        "\n",
        "\n",
        "fmnist_dataset_train = torchvision.datasets.FashionMNIST(\n",
        "    root_path, train=True, transform=train_transform, target_transform=None, download=download\n",
        ")\n",
        "fmnist_dataset_test = torchvision.datasets.FashionMNIST(\n",
        "    root_path, train=False, transform=test_transform, target_transform=None, download=download\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "71YP0SPwTIxD"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    fmnist_dataset_train, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    fmnist_dataset_test, batch_size=256, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_YFmF7NTWrQ",
        "outputId": "69a43b17-c4b1-4f04-c4b8-c5dd01747e0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(fmnist_dataset_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHca15bOTY4B",
        "outputId": "7b12ffd0-f725-4d09-fe54-08581d734ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128])\n",
            "128\n"
          ]
        }
      ],
      "source": [
        "for img, label in train_loader:\n",
        "    print(img.shape)\n",
        "    # print(img)\n",
        "    print(label.shape)\n",
        "    print(label.size(0))\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6OOOffHTfX5"
      },
      "source": [
        "### Task 1\n",
        "Train a network that achieves $\\geq 0.885$ test accuracy. It's fine to use only Linear (`nn.Linear`) layers and activations/dropout/batchnorm. Convolutional layers might be a great use, but we will meet them a bit later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ftpkTjxlTcFx"
      },
      "outputs": [],
      "source": [
        "class TinyNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28 * 28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),  # This layer converts image into a vector to use Linear layers afterwards\n",
        "            nn.Linear(input_shape, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 32),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(32, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        out = self.model(inp)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3zofW2jTDa9",
        "outputId": "06770db6-c551-4b29-998f-f89b48e27ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                  [-1, 512]         401,920\n",
            "              ReLU-3                  [-1, 512]               0\n",
            "           Dropout-4                  [-1, 512]               0\n",
            "            Linear-5                   [-1, 32]          16,416\n",
            "       BatchNorm1d-6                   [-1, 32]              64\n",
            "         LeakyReLU-7                   [-1, 32]               0\n",
            "            Linear-8                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 418,730\n",
            "Trainable params: 418,730\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.02\n",
            "Params size (MB): 1.60\n",
            "Estimated Total Size (MB): 1.62\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torchsummary.summary(TinyNeuralNetwork().to(device), (28 * 28,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "544PGKEnjPr5"
      },
      "source": [
        "Your experiments come here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3POFj90Ti-6",
        "outputId": "71e95f71-dde0-4447-adb9-4a9553494c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/40, Loss: 0.5969, Train Accuracy: 78.88%, Test Accuracy: 84.31%\n",
            "Epoch: 2/40, Loss: 0.4535, Train Accuracy: 83.50%, Test Accuracy: 85.31%\n",
            "Epoch: 3/40, Loss: 0.4255, Train Accuracy: 84.34%, Test Accuracy: 85.39%\n",
            "Epoch: 4/40, Loss: 0.4044, Train Accuracy: 85.10%, Test Accuracy: 86.02%\n",
            "Epoch: 5/40, Loss: 0.3894, Train Accuracy: 85.68%, Test Accuracy: 86.59%\n",
            "Epoch: 6/40, Loss: 0.3824, Train Accuracy: 85.75%, Test Accuracy: 86.68%\n",
            "Epoch: 7/40, Loss: 0.3701, Train Accuracy: 86.30%, Test Accuracy: 87.08%\n",
            "Epoch: 8/40, Loss: 0.3592, Train Accuracy: 86.58%, Test Accuracy: 87.10%\n",
            "Epoch: 9/40, Loss: 0.3581, Train Accuracy: 86.58%, Test Accuracy: 86.79%\n",
            "Epoch: 10/40, Loss: 0.3475, Train Accuracy: 87.00%, Test Accuracy: 87.46%\n",
            "Epoch: 11/40, Loss: 0.3443, Train Accuracy: 87.13%, Test Accuracy: 87.64%\n",
            "Epoch: 12/40, Loss: 0.3341, Train Accuracy: 87.49%, Test Accuracy: 87.90%\n",
            "Epoch: 13/40, Loss: 0.3325, Train Accuracy: 87.45%, Test Accuracy: 87.92%\n",
            "Epoch: 14/40, Loss: 0.3312, Train Accuracy: 87.70%, Test Accuracy: 87.94%\n",
            "Epoch: 15/40, Loss: 0.3239, Train Accuracy: 87.86%, Test Accuracy: 87.87%\n",
            "Epoch: 16/40, Loss: 0.3213, Train Accuracy: 88.03%, Test Accuracy: 88.27%\n",
            "Epoch: 17/40, Loss: 0.3141, Train Accuracy: 88.18%, Test Accuracy: 88.34%\n",
            "Epoch: 18/40, Loss: 0.3123, Train Accuracy: 88.19%, Test Accuracy: 88.29%\n",
            "Epoch: 19/40, Loss: 0.3093, Train Accuracy: 88.30%, Test Accuracy: 88.33%\n",
            "Epoch: 20/40, Loss: 0.3078, Train Accuracy: 88.32%, Test Accuracy: 87.99%\n",
            "Epoch: 21/40, Loss: 0.3043, Train Accuracy: 88.64%, Test Accuracy: 88.55%\n",
            "Epoch: 22/40, Loss: 0.3009, Train Accuracy: 88.86%, Test Accuracy: 88.65%\n",
            "Epoch: 23/40, Loss: 0.3008, Train Accuracy: 88.78%, Test Accuracy: 88.33%\n",
            "Epoch: 24/40, Loss: 0.2952, Train Accuracy: 88.92%, Test Accuracy: 88.56%\n",
            "Epoch: 25/40, Loss: 0.2936, Train Accuracy: 88.94%, Test Accuracy: 88.18%\n",
            "Epoch: 26/40, Loss: 0.2928, Train Accuracy: 88.91%, Test Accuracy: 88.63%\n",
            "Epoch: 27/40, Loss: 0.2906, Train Accuracy: 89.05%, Test Accuracy: 88.48%\n",
            "Epoch: 28/40, Loss: 0.2891, Train Accuracy: 89.16%, Test Accuracy: 88.66%\n",
            "Epoch: 29/40, Loss: 0.2856, Train Accuracy: 89.22%, Test Accuracy: 88.77%\n",
            "Epoch: 30/40, Loss: 0.2845, Train Accuracy: 89.21%, Test Accuracy: 88.87%\n",
            "Epoch: 31/40, Loss: 0.2821, Train Accuracy: 89.33%, Test Accuracy: 88.42%\n",
            "Epoch: 32/40, Loss: 0.2819, Train Accuracy: 89.29%, Test Accuracy: 88.58%\n",
            "Epoch: 33/40, Loss: 0.2833, Train Accuracy: 89.39%, Test Accuracy: 88.80%\n",
            "Epoch: 34/40, Loss: 0.2779, Train Accuracy: 89.57%, Test Accuracy: 88.66%\n",
            "Epoch: 35/40, Loss: 0.2747, Train Accuracy: 89.75%, Test Accuracy: 88.90%\n",
            "Epoch: 36/40, Loss: 0.2730, Train Accuracy: 89.81%, Test Accuracy: 88.85%\n",
            "Epoch: 37/40, Loss: 0.2754, Train Accuracy: 89.63%, Test Accuracy: 88.82%\n",
            "Epoch: 38/40, Loss: 0.2737, Train Accuracy: 89.63%, Test Accuracy: 88.96%\n",
            "Epoch: 39/40, Loss: 0.2744, Train Accuracy: 89.71%, Test Accuracy: 88.96%\n",
            "Epoch: 40/40, Loss: 0.2701, Train Accuracy: 89.76%, Test Accuracy: 88.77%\n"
          ]
        }
      ],
      "source": [
        "model = TinyNeuralNetwork().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-6)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs_num = 40\n",
        "\n",
        "for epoch in range(epochs_num):\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        opt.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_func(output, target)\n",
        "\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        train_correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy = 100. * train_correct / len(train_loader.dataset)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f'Epoch: {epoch+1}/{epochs_num}, Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ISqkjmCPB1"
      },
      "source": [
        "### Task 2: Overfit it.\n",
        "Build a network that will overfit to this dataset. Demonstrate the overfitting in the appropriate way (e.g. plot loss and accurasy on train and test set w.r.t. network complexity).\n",
        "\n",
        "*Note:* you also might decrease the size of `train` dataset to enforce the overfitting and speed up the computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "H12uAWiGBwJx"
      },
      "outputs": [],
      "source": [
        "class OverfittingNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28 * 28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_shape, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        out = self.model(inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgXAKCpvCwqH",
        "outputId": "10b72684-9e2c-4161-8894-dc790d7f7152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                 [-1, 1024]         803,840\n",
            "              ReLU-3                 [-1, 1024]               0\n",
            "            Linear-4                   [-1, 32]          32,800\n",
            "              ReLU-5                   [-1, 32]               0\n",
            "            Linear-6                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 836,970\n",
            "Trainable params: 836,970\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.02\n",
            "Params size (MB): 3.19\n",
            "Estimated Total Size (MB): 3.22\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torchsummary.summary(OverfittingNeuralNetwork().to(device), (28 * 28,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8Rq0PaqTDa9"
      },
      "outputs": [],
      "source": [
        "model = OverfittingNeuralNetwork().to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Your experiments, come here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvUvq5oTDa-"
      },
      "source": [
        "### Task 3: Fix it.\n",
        "Fix the overfitted network from the previous step (at least partially) by using regularization techniques (Dropout/Batchnorm/...) and demonstrate the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFH70SlOTDa-"
      },
      "outputs": [],
      "source": [
        "class FixedNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=28 * 28, num_classes=10, input_channels=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),  # This layer converts image into a vector to use Linear layers afterwards\n",
        "            # Your network structure comes here\n",
        "            nn.Linear(input_shape, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        out = self.model(inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dTugjoBTDa-"
      },
      "outputs": [],
      "source": [
        "torchsummary.summary(FixedNeuralNetwork().to(device), (28 * 28,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1wgr7dKTDa-"
      },
      "outputs": [],
      "source": [
        "model = FixedNeuralNetwork().to(device)\n",
        "opt = # YOUR CODE HERE\n",
        "loss_func = # YOUR CODE HERE\n",
        "\n",
        "# Your experiments, come here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMui_uLJ7G0d"
      },
      "source": [
        "### Conclusions:\n",
        "_Write down small report with your conclusions and your ideas._"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Overfit it.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}